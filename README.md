Noise interference in aircraft communication systems poses significant challenges to the clarity and accuracy of audio transmissions, often compromising safety and operational efficiency. 
This project introduces a deep learning-based approach to address the problem, leveraging advanced autoencoder and hybrid LSTM-CNN architectures.
The system focuses on denoising audio spectrograms, enabling real-time and reliable communication even in noisy aviation environments.


The project explored multiple architectures, including 2-layer and 3-layer convolutional autoencoders and an LSTM-CNN hybrid model. 
The autoencoders focused on spatial feature extraction from spectrograms, while the LSTM-CNN hybrid integrated temporal sequence learning for enhanced denoising.
Training and evaluation were conducted using metrics like Mean Absolute Error (MAE), Mean Squared Error (MSE), and Signal-to-Noise Ratio (SNR). 


Among the tested models, the 2-layer convolutional autoencoder emerged as the most effective, achieving the lowest MAE of 0.3617 and MSE of 5.5705. 
Its simplicity and efficiency made it superior in handling the diverse noise conditions present in the dataset. Visual and quantitative evaluations validated the system's effectiveness.
Clean spectrograms generated by the models showed substantial noise suppression while preserving the integrity of speech components. 


The results highlight the practical applicability of convolutional autoencoders for real-time noise reduction in aviation. 
Furthermore, post processing steps, including the use of Inverse Short-Time Fourier Transform (ISTFT) and smoothing filters, enhanced the output quality, ensuring clear audio reconstruction suitable for communication.

This work underscores the potential of deep learning in addressing critical challenges in aviation communication. By focusing on spatial and temporal features of noisy spectrograms, the proposed system ensures robust denoising, paving the way for safer and more efficient air travel. 
